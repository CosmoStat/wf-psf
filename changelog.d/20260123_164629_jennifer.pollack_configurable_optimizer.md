<!--
A new scriv changelog fragment.

Uncomment the section that is right (remove the HTML comment wrapper).
For top level release notes, leave all the headers commented out.
-->

<!--
### Breaking changes

- A bullet item for the Breaking changes category.

-->

### New features

- Added configurable optimizer selection system via new `optimizer.py` module with `get_optimizer` function
- Optimizer configuration now supports multiple input types: `RecursiveNamespace` from configs, dictionaries, or string names
- Added support for hyperparameter overrides (learning rate, beta1/beta2, epsilon, amsgrad) via YAML or programmatic configuration
- RectifiedAdam optimizer now dynamically imports TensorFlow Addons only when explicitly specified in configuration


### Bug fixes

- Fixed TensorFlow 2.11 compatibility by automatically using `tf.keras.optimizers.legacy.Adam` for TF < 2.11


<!--
### Performance improvements

- A bullet item for the Performance improvements category.

-->

### Internal changes

- Refactored `build_PSF_model` to accept either Keras optimizer instances or configuration passed through `get_optimizer`
- Added `interpolation.py` and `types.py` modules with vendored code from TensorFlow Addons repository
- Replaced `tfa.image.interpolate_spline` with local `tfa_interpolate_spline_rbf` implementation
- Added comprehensive unit tests in `test_optimizer.py` and `test_interpolation.py`
- Updated README and added THIRD_PARTY_LICENSE directory with TensorFlow Addons license
- Training now runs on TensorFlow 2.11 without requiring TensorFlow Addons installation
- Removed TensorFlow Addons as a required dependency; RectifiedAdam optimizer now requires explicit TFA installation if needed
